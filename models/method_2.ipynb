{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('/Users/b_eebs/tf-keras/ZINC/adj/0.npy')\n",
    "features = np.load('/Users/b_eebs/tf-keras/ZINC/features/0.npy')\n",
    "test = (np.load('/Users/b_eebs/tf-keras/ZINC/logP.npy')[0:10000]).astype(float) #takes the first 10,000 molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is the implementation that I started with, but that I won't continue since it doesn't utilize the user-friendliness of keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class nameTBD: \n",
    "    \n",
    "    models = ['gcn', 'gcn_a', 'gcn_g', 'gcn_ag']\n",
    "    \n",
    "    def __init__(self,num_epoch,num_layers,batch_size,model,adjacency,features,properties,weights,bias):\n",
    "        # each model will need all of this information to implement \n",
    "        # instance variables\n",
    "        '''\n",
    "        arguments & public attributes\n",
    "        user modified\n",
    "        '''\n",
    "        self.num_epoch = num_epoch\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.adjacency = K.placeholder(shape = [self.batch_size,50,50], dtype = 'float64')\n",
    "        self.features = K.placeholder(shape = [self.batch_size,50,58], dtype = 'float64')\n",
    "        self.properties = K.placeholder(shape = [self.batch_size], dtype = 'float64')\n",
    "        self.weights = 2 #change\n",
    "        self.bias = 3 #change \n",
    "        self.forward_prop()\n",
    "        \n",
    "    def forward_prop(self):\n",
    "        #here I want to implement the forward propogation rule for the training data and compute the loss\n",
    "        self.adjacency = K.cast(self.adjacency, dtype = 'float64')\n",
    "        self.features = K.cast(self.features, dtype = 'float64')\n",
    "        self.properties = K.cast(self.properties, dtype = 'float64')\n",
    "        #models = ['gcn', 'gcn_a', 'gcn_g', 'gcn_ag']\n",
    "        if self.model == nameTBD.models[0]:\n",
    "            self.weight = get_W_B()\n",
    "            #self._features = func_to_gcn(self.features,self.adjacency,self.num_layers)\n",
    "            \n",
    "        elif self.model == nameTBD.models[1]:\n",
    "            print('no')\n",
    "            #self._features = func_to_gcn_att(self.features,self.adjacency,self.num_layers)\n",
    "        elif self.model == nameTBD.models[2]:\n",
    "            print('no')\n",
    "            #self._features = func_to_gcn_gate(self.features,self.adjacency,self.num_layers)\n",
    "        elif self.model == nameTBD.models[3]:\n",
    "            print('no')\n",
    "            #self._features = func_to_agcn(self.features,self.adjacency,self.num_layers)\n",
    "        else: \n",
    "            raise ValueError('not a valid model')\n",
    "            \n",
    "    def get_Weight_Bias(self,adjacency,features,num_layers,model):\n",
    "        \n",
    "        # this process occurs for all models -------------\n",
    "        num_atoms = int(K.shape(adjacency)[1])\n",
    "        input_dim = int(K.shape(adjacency)[2]) # number of input molecules\n",
    "        hidden_dim = [] # contains input and all hidden layers\n",
    "        hidden_dim.append(input_dim)\n",
    "        for layers in num_layers:\n",
    "            # 32 is the output of each hidden layer\n",
    "            hidden_dim.append(32)\n",
    "        #-------------------------------------------------\n",
    "        _adjacency = adjacency\n",
    "        #conjuring the weights and bias for gcn and gcn+gate are the same\n",
    "        '''\n",
    "        if model == nameTBD.model[0] or model == nameTBD.model[2]:\n",
    "            for i in range(len(hidden_dim)-1):\n",
    "                weight = ### would have to call upon the weights and biases like Ryu et al. did\n",
    "                bias = ###\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #def backprop():\n",
    "        #here I want to implement gradient descent and optimization\n",
    "        \n",
    "    \n",
    "    #after the above two methods, I should have updated features and weights to feed into the next layer.\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a valid model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4134902b791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnameTBD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gcn_ah'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4915255b93f3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_epoch, num_layers, batch_size, model, adjacency, features, properties, weights, bias)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m#change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#change\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4915255b93f3>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#self._features = func_to_agcn(self.features,self.adjacency,self.num_layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not a valid model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_Weight_Bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madjacency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not a valid model"
     ]
    }
   ],
   "source": [
    "model1 = nameTBD(100,7,100,'gcn_ah',adj,features,test,3,4)\n",
    "model1.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
