{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I translate GCN in tensorflow to GCN in tensorflow.keras\n",
    "### Starting with 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc2\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# tf and tf keras versions\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods are functions associated with a class\n",
    "# the data are the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, adjacency, features, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.features = tf.placeholder(shape = [self.batch_size,50,58], dtype = 'float64')\n",
    "        self.adjacency = tf.placeholder(shape = [self.batch_size,50,50], dtype = 'float64')\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_atoms = int(features.get_shape()[1])\n",
    "        input_dim = int(features.get_shape()[2])\n",
    "        shape = []\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    \n",
    "    # Make sure to call the `build` method at the end\n",
    "    super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "      def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "num_atoms = int(features.get_shape()[1])\n",
    "input_dim = int(features.get_shape()[2])\n",
    "hidden_dim = [input_dim]\n",
    "MyLayer(32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#for i in range(num_layers):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is not what we, we mant to make things easier with keras\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "what will each model initially require?\n",
    "\n",
    "class nameTBD: \n",
    "    \n",
    "    models = ['gcn', 'gcn_a', 'gcn_g', 'gcn_ag']\n",
    "    \n",
    "    def __init__(self,num_epoch,num_layers,batch_size,model,adjacency,features,properties,weights,bias):\n",
    "        # each model will need all of this information to implement \n",
    "        # instance variables\n",
    "        '''\n",
    "        arguments & public attributes\n",
    "        user modified\n",
    "        '''\n",
    "        self.num_epoch = num_epoch\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.model = model\n",
    "        self.adjacency = K.placeholder(shape = [self.batch_size,50,50], dtype = 'float64')\n",
    "        self.features = K.placeholder(shape = [self.batch_size,50,58], dtype = 'float64')\n",
    "        self.properties = K.placeholder(shape = [self.batch_size], dtype = 'float64')\n",
    "        self.weights = 2 #change\n",
    "        self.bias = 3 #change \n",
    "        self.forward_prop()\n",
    "        \n",
    "    def forward_prop(self):\n",
    "        #here I want to implement the forward propogation rule for the training data and compute the loss\n",
    "        self.adjacency = K.cast(self.adjacency, dtype = 'float64')\n",
    "        self.features = K.cast(self.features, dtype = 'float64')\n",
    "        self.properties = K.cast(self.properties, dtype = 'float64')\n",
    "        #models = ['gcn', 'gcn_a', 'gcn_g', 'gcn_ag']\n",
    "        if self.model == nameTBD.models[0]:\n",
    "            self.weight = get_W_B()\n",
    "            #self._features = func_to_gcn(self.features,self.adjacency,self.num_layers)\n",
    "            \n",
    "        elif self.model == nameTBD.models[1]:\n",
    "            print('no')\n",
    "            #self._features = func_to_gcn_att(self.features,self.adjacency,self.num_layers)\n",
    "        elif self.model == nameTBD.models[2]:\n",
    "            print('no')\n",
    "            #self._features = func_to_gcn_gate(self.features,self.adjacency,self.num_layers)\n",
    "        elif self.model == nameTBD.models[3]:\n",
    "            print('no')\n",
    "            #self._features = func_to_agcn(self.features,self.adjacency,self.num_layers)\n",
    "        else: \n",
    "            raise ValueError('not a valid model')\n",
    "            \n",
    "    def get_Weight_Bias(self,adjacency,features,num_layers,model):\n",
    "        \n",
    "        # this process occurs for all models -------------\n",
    "        num_atoms = int(K.shape(adjacency)[1])\n",
    "        input_dim = int(K.shape(adjacency)[2]) # number of input molecules\n",
    "        hidden_dim = [] # contains input and all hidden layers\n",
    "        hidden_dim.append(input_dim)\n",
    "        for layers in num_layers:\n",
    "            # 32 is the output of each hidden layer\n",
    "            hidden_dim.append(32)\n",
    "        #-------------------------------------------------\n",
    "        _adjacency = adjacency\n",
    "        #conjuring the weights and bias for gcn and gcn+gate are the same\n",
    "        if model == nameTBD.model[0] or model == nameTBD.model[2]:\n",
    "            for i in range(len(hidden_dim)-1):\n",
    "                weight = \n",
    "                bias = \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #def backprop():\n",
    "        #here I want to implement gradient descent and optimization\n",
    "        \n",
    "    \n",
    "    #after the above two methods, I should have updated features and weights to feed into the next layer.\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('/Users/b_eebs/tf-keras/ZINC/adj/0.npy')\n",
    "features = np.load('/Users/b_eebs/tf-keras/ZINC/features/0.npy')\n",
    "test = (np.load('/Users/b_eebs/tf-keras/ZINC/logP.npy')[0:10000]).astype(float) #takes the first 10,000 molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not a valid model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f4134902b791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnameTBD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gcn_ah'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-4f95e0dbaebd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_epoch, num_layers, batch_size, model, adjacency, features, properties, weights, bias)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-4f95e0dbaebd>\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#self._features = func_to_agcn(self.features,self.adjacency,self.num_layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not a valid model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#def get_weights(self):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not a valid model"
     ]
    }
   ],
   "source": [
    "model1 = nameTBD(100,7,100,'gcn_ah',adj,features,test,3,4)\n",
    "model1.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "model1 = nameTBD(100,7,100,'gcn',adj,features,test,3,4)\n",
    "model1.forward_prop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
