{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I translate GCN in tensorflow to GCN in tensorflow.keras\n",
    "### This is the current method i'm focusing on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0-rc2\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# tf and tf keras versions\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods are functions associated with a class\n",
    "# the data are the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.load('/Users/b_eebs/tf-keras/ZINC/adj/0.npy')\n",
    "features = np.load('/Users/b_eebs/tf-keras/ZINC/features/0.npy')\n",
    "test = (np.load('/Users/b_eebs/tf-keras/ZINC/logP.npy')[0:10000]).astype(float) #takes the first 10,000 molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class allows us to build the weight and biases for each convolutional layer and also each model. After building the biases in the build method, I will perform the matrix multiplications in the call method for each model. The cell below will iteratively call upon all layers, until the whole model is build. The model will then be compiled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "class MyLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, adjacency, features, weight_shape, bias_shape, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.features = tf.placeholder(shape = [100,50,58], dtype = 'float64')\n",
    "        self.adjacency = tf.placeholder(shape = [100,50,50], dtype = 'float64')\n",
    "        self.weight_shape = weight_shape\n",
    "        self.bias_shape = bias_shape\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    # still have to add attention weights\n",
    "    def build(self):\n",
    "        num_atoms = int(self.features.shape[1])\n",
    "        input_dim = int(self.features.shape[2])\n",
    "        weight_shape = self.weight_shape\n",
    "        bias_shape = self.bias_shape\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=weight_shape,\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        \n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                shape=(bias_shape),\n",
    "                                initializer='zeros',\n",
    "                                trainable=True)\n",
    "    \n",
    "    # Make sure to call the `build` method at the end\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "    \n",
    "    #here is where I will implement all models, which will be built in another script. \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyLayer object at 0xb473b19e8>\n",
      "<__main__.MyLayer object at 0xb473b19e8>\n",
      "<__main__.MyLayer object at 0xb473b19e8>\n"
     ]
    }
   ],
   "source": [
    "#this is where all models will be built\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "num_atoms = int(features.shape[1])\n",
    "input_dim = int(features.shape[2])\n",
    "hidden_dim = [input_dim]\n",
    "num_layers=3\n",
    "for i in range(num_layers):\n",
    "    hidden_dim.append(32)\n",
    "    print(MyLayer(32,adj,features,[i,i+1],[i+1])    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
